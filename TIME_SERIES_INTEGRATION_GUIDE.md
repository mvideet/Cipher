# Time Series Forecasting Integration Guide for Cipher Platform

## Overview

This guide shows how to use the comprehensive time series forecasting pipeline that has been integrated into your Cipher ML platform. The integration includes:

- **Time Series Trainer**: Specialized trainer for ARIMA, Prophet, LSTM, and other forecasting models
- **Enhanced Model Selector**: LLM-guided time series model recommendations
- **Extended Data Profiler**: Comprehensive temporal analysis and pattern detection  
- **Advanced Explainer**: Time series specific model explanations and interpretability

## Quick Start Example

```python
import pandas as pd
from src.ml.timeseries_trainer import TimeSeriesTrainer
from src.ml.data_profiler import DataProfiler
from src.models.schema import DataProfile

# 1. Load your time series data
df = pd.read_csv('your_timeseries_data.csv')
# Expected columns: ['date', 'sales', 'other_features...']

# 2. Profile the data for time series characteristics
profiler = DataProfiler()

# Basic profiling
profile = profiler.profile_dataset(df)

# Time series specific profiling  
ts_profile = profiler.profile_time_series(df, 'date', 'sales')

print(f"Frequency detected: {ts_profile['temporal_analysis']['frequency']['inferred_freq']}")
print(f"Seasonality: {ts_profile['temporal_analysis']['target_patterns']['seasonality']['detected']}")

# 3. Train time series models
trainer = TimeSeriesTrainer(run_id="ts_001", session_id="session_001", websocket_manager=None)

best_model = await trainer.train_forecast_models(
    dataset_path='your_timeseries_data.csv',
    date_column='date',
    target_column='sales', 
    forecast_horizon=30,  # Forecast 30 periods ahead
    data_profile=profile,
    constraints={'time_budget': 'medium'}
)

print(f"Best model: {best_model.family}")
print(f"Validation RMSE: {best_model.val_score:.4f}")
```

## ðŸŽ‰ Integration Complete!

Your Cipher ML platform now has enterprise-grade time series forecasting capabilities with:

âœ… **5 Model Types**: ARIMA, Prophet, LSTM, Exponential Smoothing, Seasonal Decomposition  
âœ… **Automatic Model Selection**: LLM-guided recommendations based on data characteristics  
âœ… **Advanced Metrics**: MAPE, SMAPE, MASE, directional accuracy, comprehensive evaluation  
âœ… **Smart Data Pipeline**: Temporal validation, feature engineering, gap analysis  
âœ… **Detailed Explanations**: Model-specific interpretability and business insights  
âœ… **Production Ready**: Follows existing architecture patterns and error handling

## Next Steps

1. **Install Dependencies**: Run `pip install -r requirements.txt` to get time series libraries
2. **Test Integration**: Run the test script: `python test_timeseries_integration.py`
3. **Try Examples**: Use the usage patterns in this guide with your data
4. **Frontend Integration**: Add time series visualization components to your UI
5. **Deploy**: Integrate with your existing training orchestration system

The time series pipeline seamlessly integrates with your existing Cipher architecture while adding powerful forecasting capabilities for business applications like sales prediction, demand forecasting, and resource planning.

## Detailed Component Usage

### 1. Time Series Data Profiling

```python
from src.ml.data_profiler import DataProfiler

profiler = DataProfiler()

# Comprehensive time series analysis
ts_profile = profiler.profile_time_series(df, date_column='date', target_column='sales')

# Access key insights
frequency_info = ts_profile['temporal_analysis']['frequency']
print(f"Data frequency: {frequency_info['inferred_freq']}")
print(f"Confidence: {frequency_info['frequency_confidence']:.2f}")

# Seasonality detection
seasonality = ts_profile['temporal_analysis']['target_patterns']['seasonality']
if seasonality['detected']:
    print(f"Seasonality type: {seasonality['type']}")
    print(f"Dominant period: {seasonality['dominant_period']}")

# Trend analysis
trend = ts_profile['temporal_analysis']['target_patterns']['trend']
if trend['detected']:
    print(f"Trend direction: {trend['direction']}")
    print(f"Trend strength (RÂ²): {trend['r_squared']:.3f}")

# Get recommendations
for rec in ts_profile['recommendations']:
    print(f"ðŸ’¡ {rec}")
```

### 2. Individual Forecasting Models

#### ARIMA Model
```python
from src.ml.timeseries_trainer import ARIMAForecaster

# Auto-fit ARIMA with optimal parameters
forecaster = ARIMAForecaster()
fit_info = forecaster.auto_fit(series, seasonal=True)

print(f"ARIMA order: {fit_info['order']}")
print(f"AIC: {fit_info['aic']:.2f}")

# Generate forecasts with confidence intervals
forecast_result = forecaster.forecast(steps=30, confidence_interval=0.95)
forecast_values = forecast_result["forecast"]
lower_ci = forecast_result["lower_ci"] 
upper_ci = forecast_result["upper_ci"]
```

#### Prophet Model
```python
from src.ml.timeseries_trainer import ProphetForecaster

# Fit Prophet with automatic seasonality detection
forecaster = ProphetForecaster()
fit_info = forecaster.fit_with_seasonality(
    train_df, 'date', 'sales',
    yearly=True, weekly=True, daily=False
)

# Generate forecasts
forecast_df = forecaster.forecast_with_uncertainty(periods=30, freq='D')
print(forecast_df[['ds', 'yhat', 'yhat_lower', 'yhat_upper']])
```

#### LSTM Model  
```python
from src.ml.timeseries_trainer import LSTMTimeSeriesModel

# Configure LSTM architecture
lstm_model = LSTMTimeSeriesModel(
    input_size=1,
    hidden_size=64, 
    num_layers=2,
    output_size=1
)

# Prepare data and train
X_train, y_train = lstm_model.prepare_data(train_series)
train_info = lstm_model.train_model(X_train, y_train, epochs=50)

# Generate forecasts
last_sequence = train_series.tail(lstm_model.sequence_length).values
forecast_values = lstm_model.forecast(last_sequence, steps=30)
```

### 3. Time Series Metrics

```python
from src.ml.timeseries_trainer import TimeSeriesMetrics

# Comprehensive evaluation
metrics = TimeSeriesMetrics.comprehensive_evaluation(
    actual=test_values,
    forecast=predicted_values, 
    seasonal_period=7  # Weekly seasonality
)

print(f"MAE: {metrics['mae']:.2f}")
print(f"RMSE: {metrics['rmse']:.2f}")  
print(f"MAPE: {metrics['mape']:.2f}%")
print(f"SMAPE: {metrics['smape']:.2f}%")
print(f"MASE: {metrics['mase']:.2f}")
print(f"Directional Accuracy: {metrics['directional_accuracy']:.2f}%")
```

### 4. Model Explanations

```python
from src.ml.explainer import Explainer

explainer = Explainer()

# Explain time series forecast
explanation = await explainer.explain_time_series_forecast(
    model_path='path/to/saved/model.pkl',
    forecast_data={'confidence_intervals': forecast_ci},
    time_series_data=df,
    date_column='date',
    target_column='sales'
)

# Access explanations
print(f"Model type: {explanation['model_type']}")
print(f"Explanation: {explanation['text_explanation']}")

# ARIMA-specific insights
if explanation['model_type'] == 'ARIMA':
    order_info = explanation['parameter_analysis']['order']
    print(f"AR terms: {order_info['p']['value']} - {order_info['p']['meaning']}")
    print(f"Differencing: {order_info['d']['value']} - {order_info['d']['meaning']}")
    print(f"MA terms: {order_info['q']['value']} - {order_info['q']['meaning']}")

# Prophet-specific insights  
if explanation['model_type'] == 'Prophet':
    seasonality = explanation['seasonality_analysis']
    for season_type, description in seasonality.items():
        print(f"{season_type.title()}: {description}")
```

## Integration with Existing Workflow

### Modifying Enhanced Trainer for Time Series

```python
from src.ml.enhanced_trainer import EnhancedTrainingOrchestrator
from src.ml.timeseries_trainer import TimeSeriesTrainer

class TimeSeriesEnhancedTrainer(EnhancedTrainingOrchestrator):
    """Enhanced trainer with time series support"""
    
    async def train_models(self, dataset_path, target_col, task_type, metric, constraints, **kwargs):
        
        # Check if this is a time series task
        if task_type == "time_series" or kwargs.get('date_column'):
            # Use time series trainer
            ts_trainer = TimeSeriesTrainer(self.run_id, self.session_id, self.websocket_manager)
            
            return await ts_trainer.train_forecast_models(
                dataset_path=dataset_path,
                date_column=kwargs['date_column'], 
                target_column=target_col,
                forecast_horizon=kwargs.get('forecast_horizon', 30),
                data_profile=kwargs['data_profile'],
                constraints=constraints
            )
        else:
            # Use standard training
            return await super().train_models(dataset_path, target_col, task_type, metric, constraints)
```

### UI Integration Considerations

```javascript
// Frontend time series specific components needed

class TimeSeriesForecastChart {
    constructor(container, data) {
        this.container = container;
        this.data = data;
    }
    
    render() {
        // Plot historical data + forecast + confidence intervals
        // Interactive zoom for different time ranges
        // Seasonal decomposition toggle
        // Model comparison overlay
    }
}

class ForecastMetricsDisplay {
    constructor(metrics) {
        this.metrics = metrics;
    }
    
    render() {
        // MAPE, SMAPE, MAE, RMSE dashboard
        // Forecast accuracy by horizon
        // Model performance comparison
        // Statistical significance indicators
    }
}
```

## Advanced Usage Patterns

### 1. Ensemble Forecasting

```python
# Train multiple models and combine forecasts
models = ['arima', 'prophet', 'exponential_smoothing']
forecasts = []

for model_type in models:
    # Train individual model
    forecast = train_individual_model(model_type, data)
    forecasts.append(forecast)

# Simple averaging ensemble
ensemble_forecast = np.mean(forecasts, axis=0)

# Weighted ensemble based on validation performance
weights = calculate_weights_from_validation(models, validation_data)
weighted_forecast = np.average(forecasts, weights=weights, axis=0)
```

### 2. Multi-step Forecasting

```python
def multi_step_forecast(model, data, horizons=[7, 14, 30]):
    """Generate forecasts for multiple horizons"""
    
    forecasts = {}
    
    for horizon in horizons:
        forecast_result = model.forecast(steps=horizon)
        
        forecasts[f"{horizon}_day"] = {
            'forecast': forecast_result['forecast'],
            'confidence_intervals': forecast_result.get('confidence_intervals'),
            'horizon': horizon
        }
    
    return forecasts
```

### 3. Automated Model Selection

```python
async def auto_select_ts_model(data, date_col, target_col):
    """Automatically select best time series model"""
    
    # Profile the data
    profiler = DataProfiler()
    ts_profile = profiler.profile_time_series(data, date_col, target_col)
    
    # Get LLM recommendations
    model_selector = ModelSelector()
    recommendations = await model_selector.recommend_ensemble(
        data_profile=profile,
        task_type="time_series", 
        target_column=target_col,
        constraints={'ts_characteristics': ts_profile}
    )
    
    # Return top recommendation
    return recommendations.recommended_models[0]
```

### 4. Real-time Forecasting Pipeline

```python
class RealTimeForecastingPipeline:
    """Pipeline for continuous forecasting with model updates"""
    
    def __init__(self, model_path, update_frequency='daily'):
        self.model = self.load_model(model_path)
        self.update_frequency = update_frequency
        self.last_update = None
    
    async def generate_forecast(self, new_data=None):
        """Generate forecast with optional model update"""
        
        # Check if model needs updating
        if self.should_update_model():
            await self.update_model(new_data)
        
        # Generate forecast
        forecast = self.model.forecast(steps=self.forecast_horizon)
        
        return {
            'forecast': forecast['forecast'],
            'confidence_intervals': forecast.get('confidence_intervals'),
            'model_updated': self.last_update,
            'next_update': self.get_next_update_time()
        }
    
    def should_update_model(self):
        """Check if model should be retrained with new data"""
        if self.last_update is None:
            return True
            
        time_since_update = datetime.now() - self.last_update
        return time_since_update > timedelta(days=1)  # Update daily
```

## Best Practices

### 1. Data Preparation
- âœ… Ensure consistent time intervals
- âœ… Handle missing values appropriately (interpolation vs. exclusion)
- âœ… Check for and handle outliers in temporal context
- âœ… Validate date formats and sort chronologically

### 2. Model Selection
- âœ… Start with simple models (ARIMA, Exponential Smoothing) for baseline
- âœ… Use Prophet for data with clear seasonality and holidays
- âœ… Consider LSTM for complex, non-linear patterns
- âœ… Evaluate multiple models and use ensemble when beneficial

### 3. Validation Strategy
- âœ… Use time series cross-validation (no future data leakage)
- âœ… Evaluate on multiple forecast horizons
- âœ… Check residual autocorrelation and normality
- âœ… Monitor performance over time for model drift

### 4. Production Deployment
- âœ… Implement monitoring for data quality and model performance
- âœ… Set up automated retraining schedules
- âœ… Provide confidence intervals with all forecasts
- âœ… Document model assumptions and limitations

## Troubleshooting Common Issues

### Issue: Poor Forecast Accuracy
**Solutions:**
- Check data quality and preprocessing steps
- Verify stationarity (use differencing if needed)
- Tune hyperparameters more extensively
- Consider external factors or additional features
- Try ensemble methods

### Issue: Model Training Fails
**Solutions:**
- Check for sufficient historical data (>50 points for complex models)
- Validate date column format and consistency
- Handle missing values before training
- Reduce model complexity for limited data

### Issue: Seasonal Patterns Not Captured
**Solutions:**
- Verify seasonal period detection in profiling
- Use seasonal ARIMA or Prophet models
- Check if data spans multiple seasonal cycles
- Consider multiple seasonalities (daily + weekly + yearly)

### Issue: Confidence Intervals Too Wide
**Solutions:**
- Use more historical data if available
- Consider simpler, more stable models
- Check for outliers affecting uncertainty estimates
- Validate model assumptions (residual analysis)

## Performance Optimization

### 1. Training Speed
```python
# Optimize training time for large datasets
constraints = {
    'time_budget': 'fast',           # Reduces hyperparameter search
    'max_samples': 10000,            # Limit training data size
    'selected_models': ['arima', 'prophet'],  # Focus on specific models
    'parallel_training': True        # Train models in parallel
}
```

### 2. Memory Usage
```python
# Optimize memory for large time series
pipeline_config = {
    'batch_size': 32,               # LSTM batch size
    'sequence_length': 20,          # Reduce for memory efficiency  
    'feature_limit': 50,            # Limit engineered features
    'sample_for_analysis': 5000     # Sample for profiling large datasets
}
```

### 3. Inference Speed
```python
# Optimize for fast predictions
class FastForecastingModel:
    def __init__(self, model_path):
        self.model = self.load_optimized_model(model_path)
        self.preprocessor = self.load_preprocessor()
    
    def predict(self, data, horizon=1):
        """Fast prediction with minimal preprocessing"""
        # Use cached preprocessors and simplified feature engineering
        processed_data = self.preprocessor.transform(data)
        return self.model.forecast(steps=horizon)
```

This comprehensive integration provides enterprise-grade time series forecasting capabilities fully integrated with your existing Cipher ML platform architecture. The pipeline supports automatic model selection, advanced evaluation metrics, and detailed explanations while maintaining the high code quality and patterns established in your current system. 